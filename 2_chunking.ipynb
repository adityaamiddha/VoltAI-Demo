{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ceafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "CLEAN_DIR = Path(\"data/cleaned_text\")\n",
    "OUT_DIR = Path(\"data/chunks\")\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MERGED_FILE = CLEAN_DIR / \"GLOBAL_EV_OUTLOOK_2022_2024_MERGED.txt\"\n",
    "assert MERGED_FILE.exists(), \"Merged file not found. Run data_ingestion.ipynb first.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d2f0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581689,\n",
       " '\\n\\n### SOURCE: GEVO2023_clean\\n\\nGlobal EV \\nOutlook 2023\\nCatching up with climate ambitions\\n\\nThe IEA examines the \\nfull spectrum \\nof energy issues \\nincluding oil, gas and \\ncoal supply and \\ndemand, renewa')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = MERGED_FILE.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "len(text), text[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14588c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 'GEVO2023_clean')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_by_source(merged_text: str):\n",
    "    parts = re.split(r\"\\n\\n### SOURCE:\\s*\", merged_text)\n",
    "    # first element might be empty\n",
    "    docs = []\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        # First line until newline is the source name\n",
    "        first_newline = part.find(\"\\n\")\n",
    "        source = part[:first_newline].strip()\n",
    "        body = part[first_newline:].strip()\n",
    "        docs.append((source, body))\n",
    "    return docs\n",
    "\n",
    "docs = split_by_source(text)\n",
    "len(docs), docs[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e3426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEVO2023_clean → 2023\n",
      "GlobalEVOutlook2024_clean → 2024\n",
      "GlobalEVOutlook2025_clean → 2025\n",
      "GlobalElectricVehicleOutlook2022_clean → 2022\n"
     ]
    }
   ],
   "source": [
    "def infer_year_from_source(source: str):\n",
    "    match = re.search(r\"(20\\d{2})\", source)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "for src, _ in docs:\n",
    "    print(src, \"→\", infer_year_from_source(src))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d199554",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_WORDS = 850      # size per chunk (approx)\n",
    "OVERLAP_WORDS = 150    # overlap to preserve continuity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b5d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_for_chunking(text: str) -> str:\n",
    "    # remove excessive whitespace\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]{2,}\", \" \", text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f839a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_words(text: str, chunk_words=850, overlap_words=150):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(words)\n",
    "\n",
    "    while start < n:\n",
    "        end = min(start + chunk_words, n)\n",
    "        chunk = \" \".join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        if end == n:\n",
    "            break\n",
    "\n",
    "        start = end - overlap_words  # overlap\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0f8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking documents: 100%|██████████| 4/4 [00:00<00:00, 77.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"chunk_id\": \"IEA_2024_000123\",\n",
    "  \"source\": \"GlobalEVOutlook2024_clean\",\n",
    "  \"year\": 2024,\n",
    "  \"domain\": \"EV Outlook\",\n",
    "  \"text\": \"...\"\n",
    "}\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for source, body in tqdm(docs, desc=\"Chunking documents\"):\n",
    "    year = infer_year_from_source(source)\n",
    "    body = normalize_for_chunking(body)\n",
    "\n",
    "    doc_chunks = chunk_text_by_words(body, CHUNK_WORDS, OVERLAP_WORDS)\n",
    "\n",
    "    for i, ch in enumerate(doc_chunks):\n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"IEA_{year}_{i:06d}\",\n",
    "            \"source\": source,\n",
    "            \"year\": year,\n",
    "            \"domain\": \"IEA Global EV Outlook\",\n",
    "            \"text\": ch\n",
    "        })\n",
    "\n",
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5671c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunks to: data/chunks/iea_ev_outlook_chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_path = OUT_DIR / \"iea_ev_outlook_chunks.jsonl\"\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in chunks:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ Saved chunks to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4abfd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 352\n",
      "Min words: 431\n",
      "Max words: 850\n",
      "Avg words: 846.9545454545455\n",
      "IEA_2022_000030 GlobalElectricVehicleOutlook2022_clean\n",
      "--------------------------------------------------------------------------------\n",
      "natural gas, liquefied natural gas and biomethane), liquid biofuels, synthetic and paraffinic fuels, and liquefied petroleum gas. Austria’s 2021 Mobility Master Plan outlines targets to end the sale of conventional M/HDVs under 18 tonnes by 2030, and by 2035 for those over 18 tonnes. A total of EUR 46 million (USD 54 million) was available in to support electromobility, including EUR 60 000 (USD 70 980) offered for the purchase of eligible commercial heavy-duty ZEVs and up to EUR 130 000 (USD 153 790) for buses. EUR 46 million (USD 54 million) was available in 2021 to support electromobility, including EUR 60 000 (USD 70 980) for the purchase of eligible commercial heavy-duty ZEVs and up to EUR 130 000 for buses (USD 153 790). Spain activated EUR 400 million (USD 473 million) to promote heavy road transport decarbonisation, which funds purchase subsidies for HDVs of up to EUR 190 000 (USD 224 770) (subsidy level varies based on vehicle class and beneficiary type). India State-owned Convergence Energy Services Limited aims to procure more than 5 500 electric buses as a part of its Grand Challenge Initiative. The initiative has been launched in five major cities across India, with a \n"
     ]
    }
   ],
   "source": [
    "lengths = [len(c[\"text\"].split()) for c in chunks]\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"Min words:\", min(lengths))\n",
    "print(\"Max words:\", max(lengths))\n",
    "print(\"Avg words:\", sum(lengths)/len(lengths))\n",
    "\n",
    "\n",
    "import random\n",
    "sample = random.choice(chunks)\n",
    "print(sample[\"chunk_id\"], sample[\"source\"])\n",
    "print(\"-\"*80)\n",
    "print(sample[\"text\"][:1200])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
